<!DOCTYPE html>
<html>
<head>
    <title>Digital Intelligence Workshop Chatbot</title>
    <style>
        body { font-family: Arial; max-width: 800px; margin: 0 auto; padding: 20px; background: #f0f0f0; }
        .chat { border: 1px solid #ccc; height: 400px; overflow-y: auto; padding: 15px; background: white; margin: 10px 0; }
        .message { margin: 10px 0; padding: 8px; border-radius: 5px; }
        .user { background: #007bff; color: white; text-align: right; }
        .bot { background: #e9ecef; }
        input { width: 70%; padding: 10px; margin: 5px; }
        button { padding: 10px 15px; margin: 5px; background: #007bff; color: white; border: none; cursor: pointer; }
        .suggestions button { background: #28a745; font-size: 12px; padding: 5px 10px; }
    </style>
</head>
<body>
    <h1>ðŸ¤– Digital Intelligence Workshop Chatbot</h1>
    
    <div class="chat" id="chat">
        <div class="message bot">ðŸ‘‹ Hello! Ask me about the Digital Intelligence Workshop.</div>
    </div>
  
    <input type="text" id="input" placeholder="Type your question...">
    <button onclick="sendMessage()">Send</button>
    
    <script>
        const qaData = {"duration": "around two and half hours", "purpose": "Undertstand modern technologies in a visualised way .Motivate students in Science and technology ", "hai": "Hello I am A Chatbot to Convey details of Workshop, ask about this ", "about": "Digital intelligence workshop and Art Exhibition", "what is digital intelligence": "Digital Intelligence combines electronics, robotics, IoT, AI and ML to create smart systems that sense, think and respond.", "who": "Workshop by Indukumar and Art exhibition by Abhijith", "who conducted the workshop": "Indukumar P P - ITI Electrical, MSc Physics, PGDCA. Mobile: 9446742953", "who conducted art exhibition": "Abhijith R from Sivadrumam, Peruvaram. Mobile: 8590566698", "art exhibition conducted by whom": "Abhijith R , Sivadrumam , Peruvaram. Mobile : 8590566698", "where art exhibition conducted": "An art exhibition also arranged nearby .", "at what time art exhibition conducted": "Along with . exhibition , near by room", "time of the event": "2pm , 26-10-2025", "what is arduino": "Arduino is an open-source microcontroller that acts as robot's brain, processing sensor data and controlling motors.", "explain iot": "IoT connects devices via internet. NodeMCU (ESP8266) sends sensor data to cloud platforms like Google Sheets.", "what is w1209": "W1209 is temperature control module for incubators. Uses microcontroller + sensor + relay for automatic heating.", "ai and ml difference": "AI makes systems think like humans. ML teaches computers to learn from data without explicit programming.", "workshop location": "District Building (Jilla Mandiram), Samstha Kerala Warrier Samajam, Desam, Aluva", "art exhibition location": "Art exhibition arranged nearby the same venue - District Building, Desam, Aluva", "art exhibition artist": "Abhijith R from Sivadrumam, Peruvaram. Mobile: 8590566698. Pencil drawing, charcoal drawing, water colour painting", "who did art exhibition": "Abhijith R from Sivadrumam, Peruvaram. Mobile: 8590566698", "where art exhibition": "Art exhibition arranged nearby the workshop venue at District Building, Desam, Aluva", "contact details": "Mobile: 9446742953, Email: indukumarwarrier@gmail.com", "embedded system definition": "Specialized computer system for specific tasks. Real-time, low power, task-specific automation.", "robotics basics": "Students learned Arduino programming, sensor connections, basic movements, obstacle detection using ultrasonic sensors.", "what": "Digital intelligence workshop", "when": "2pm , 26-10-2025", "topics covered": "Advanced Electronics, Robotics using Arduino, Embedded Systems (W1209), IoT using NodeMCU, AI and Machine Learning", "what topics were covered": "Advanced Electronics, Robotics using Arduino, Embedded Systems (W1209), IoT using NodeMCU, AI and Machine Learning"};
        const keywords = {"instructor": ["teacher", "instructor", "workshop", "digital", "inttelligence"], "contact": ["contact", "phone", "mobile", "email"], "location": ["where", "place", "venue", "location", "how"], "arduino": ["arduino", "microcontroller", "robot"], "iot": ["iot", "internet", "nodemcu", "wifi", "cloud"], "ai": ["ai", "artificial", "intelligence", "ml", "machine", "learning"], "electronics": ["electronics", "components", "circuit", "sensor"], "embedded": ["embedded", "w1209", "temperature", "control"], "art": ["art", "exhibition", "drawing", "painting", "abhijith"], "art_conductor": ["who", "conducted", "art", "exhibition", "artist"], "time": ["when"], "topics": ["topics", "covered", "subjects", "learn", "taught", "subject"], "hai": ["hello", "hi", "hallo", "hlo", "you", "name", "who"], "duration": ["long", "how long", "length"], "purpose": ["need", "benefit", "motive"]};
        const pdfChunks = ["Workshop on Digital Intelligence Conducted by : Indukumar P P Qualification : ITI Electrical, Msc. Physics (Specialisation : Advanced Electronics ), PGDCA mobile : 9446742953 email : indukumarwarrier@gmail.com Arranged by : Samstha kerala warrier Samajam , Youth wing , Eranakulam District Place : District Building ( \u201c Jilla Mandiram\u201d) of Samstha kerala warrier Samajam , Eranakulam District at Desam , Aluva . Introduction The Workshop on Digital Intelligence was conducted to provide students with an opportunity to explore the technologies that are shaping our modern world. The main aim was to help school students understand and experience the basic principles of advanced electronics, robotics, Internet of Things (IoT), Artificial Intelligence (AI), and Machine Learning (ML) in an easy and practical way. In today\u2019s digital age, everything around us\u2014from mobile phones to smart homes\u2014is operated by systems that can sense, think, and respond. Understanding how these technologies work gives students the foundation to become innovators and problem-solvers. The workshop was designed to spark curiosity, promote creativity, and introduce the participants to the exciting world of digital intelligence. 1. Advanced Electronics The workshop began with a detailed introduction to advanced electronics, which forms the backbone of all digital systems. Students learned about different electronic components such as resistors, capacitors, LEDs, transistors, diodes, and sensors. They explored how these components are connected on a breadboard and how electricity flows through a circuit. Simple experiments demonstrated how sensors detect changes in the environment \u2014such as light, motion, or temperature\u2014and how these signals can be used to control output devices like buzzers or LEDs. The session also included examples of how electronic circuits are used in real life, like automatic night lamps, water-level indicators, and motion-sensitive lights. Students gained a clear understanding that electronics is not only about wires and parts\u2014it is about designing systems", "that interact intelligently with the world. 2. Robotics Using Arduino The second part of the workshop introduced students to robotics basics using Arduino, an open- source microcontroller platform. The Arduino board acts as the \u201cbrain\u201d of a robot, allowing it to process information from sensors and control motors or other devices. Students learned how to connect sensors and actuators to the Arduino and how to write simple programs to make the robot perform tasks. They experimented with basic robotic movements\u2014such as moving forward, turning, and stopping when an obstacle was detected using an ultrasonic sensor. This session helped students understand the working of real-world robots. They also developed logical and computational thinking while writing and testing their code. The hands-on nature of the session made learning enjoyable, as students could see their creations come to life through blinking lights, movement, and sensor responses. 3. Embedded System \u2013 Short Note Definition: An Embedded System is a specialized computer system designed to perform a specific task or function within a larger device. Unlike general-purpose computers, it is task-specific and often operates in real-time. Key Features: \u2022 Task-specific and automated \u2022 Real-time operation \u2022 Low power consumption \u2022 Limited memory and processing resources \u2022 High reliability Components: 1. Hardware: Microcontroller/microprocessor, sensors (input), actuators (output), memory, display. 2. Software: Firmware or application software that controls the system. Types: \u2022 Small-scale: Simple devices (digital watches, calculators) \u2022 Medium-scale: Home appliances, MP3 players \u2022 Sophisticated: Smart cars, medical devices Applications: \u2022 Consumer electronics (smart TVs, cameras) \u2022 Automobiles (engine control, airbags) \u2022 Healthcare (heart rate monitors) \u2022 Industrial automation (robots, process control) \u2022 IoT devices (smart home, wearables) Example: W1209 incubator module \u2022 Measures temperature using a sensor \u2022 Microcontroller compares with setpoint \u2022 Relay switches heater on/off \u2022 Maintains stable temperature automatically Conclusion: Embedded systems", "are everywhere in modern devices, providing automation, efficiency, and real- time control. Example explanation below W1209 Incubator Module as an Embedded System The W1209 module is a small, low-cost temperature control module widely used in incubators, aquariums, or other temperature-sensitive devices. It can automatically control heating or cooling devices based on a set temperature, making it a perfect real-world example of an embedded system. 1. Purpose The W1209 module is designed to maintain a desired temperature by turning a connected device (like a heater) on or off. \u2022 Example: In a chicken egg incubator, it keeps the temperature steady at 37\u201338\u00b0C for proper hatching. 2. Components of W1209 as an Embedded System Hardware Components 1. Microcontroller: \u2022 The module uses a built-in STC microcontroller that acts as the brain of the system. \u2022 It processes input data from the temperature sensor and decides when to turn the heater on or off. 2. Temperature Sensor: \u2022 Usually a thermistor (NTC type). \u2022 Measures the current temperature of the incubator. 3. Relay Output: \u2022 A 5V relay that acts as a switch for external devices (like heaters or fans). \u2022 The relay can turn devices on or off based on the microcontroller\u2019s instructions. 4. Display: \u2022 A 3-digit 7-segment display shows the current temperature. \u2022 Provides feedback to the user about the system\u2019s status. 5. Buttons: \u2022 SET, Up, Down buttons allow the user to program the desired temperature and adjust parameters like hysteresis (how much variation is allowed). Software Components \u2022 The module runs a simple embedded firmware stored in its microcontroller. \u2022 Functions of the firmware: 1. Read temperature from the sensor. 2. Compare the measured temperature with the setpoint. 3. Switch the relay ON if temperature is below the setpoint. 4. Switch the relay OFF if temperature is above", "the setpoint. 5. Update the display to show the current temperature. 6. Respond to button inputs for temperature adjustments. This loop repeats continuously, which is typical of real-time embedded systems. 3. Features of W1209 as an Embedded System \u2022 Task-specific: Only measures temperature and controls a device. \u2022 Real-time: Immediately reacts when the temperature crosses the threshold. \u2022 Resource-constrained: Limited memory, simple display, low-cost microcontroller. \u2022 Reliability: Maintains stable temperature over long periods. \u2022 Low power: Efficient enough to run on 5\u201312V DC power. 4. How It Works (Functional Idea) 1. User sets the desired temperature using buttons. 2. The thermistor measures the incubator\u2019s current temperature. 3. The microcontroller compares the measured temperature with the set temperature: \u2022 If temperature < setpoint \u2192 relay activates the heater \u2192 incubator warms up. \u2022 If temperature > setpoint \u2192 relay deactivates heater \u2192 incubator stops heating. 4. Display shows the current temperature continuously. 5. This cycle repeats automatically, keeping the environment within the desired range. 5. Applications \u2022 Egg incubators \u2022 Fish tanks / aquariums \u2022 Small fermentation or plant growth chambers \u2022 Any DIY project requiring temperature control 6. Why W1209 is an Embedded System \u2022 Integrated hardware + software working together for a specific function. \u2022 Real-time feedback control (temperature measurement \u2192 decision \u2192 action). \u2022 Small, dedicated, and automated system without needing external computers. 4. Internet of Things (IoT) Using NodeMCU and Google Apps Script The third session of the workshop focused on the Internet of Things (IoT), a rapidly growing technology that allows devices to connect and communicate through the internet. Students were introduced to the NodeMCU (ESP8266) microcontroller, which has built-in Wi-Fi capability. They learned how sensors connected to the NodeMCU could send real-time data to cloud platforms like Google Sheets using Google Apps Script. The participants", "created simple IoT projects that collected environmental data (such as temperature or humidity) and sent it to the internet for display and analysis. They also learned how IoT can be used to control devices remotely, such as switching a light on or off using a smartphone. The concept of IoT helped students realize how modern devices\u2014from smart home appliances to automated farms\u2014are interconnected. They also understood how IoT combines electronics, programming, and cloud computing to make the world more efficient and intelligent. 5. Artificial Intelligence (AI) and Machine Learning (ML) The final part of the workshop explored Artificial Intelligence (AI) and its close partner Machine Learning (ML) \u2014 two of the most transformative technologies of the 21st century. Students were introduced to the idea that AI is a system that can think and learn like humans. Through simple examples, they saw how AI is already present in daily life \u2014 from facial recognition in mobile phones to voice assistants like Alexa and Siri, and even in recommendation systems on YouTube and Netflix. The session explained how Machine Learning allows computers to learn automatically from data without being explicitly programmed. For example, an AI system can learn to recognize objects, predict weather, or identify handwriting by being trained on large sets of data. Students were given a basic understanding of how machine learning works: 1. Data Collection: Gathering information or samples to learn from. 2. Training: Teaching the system by feeding it data and showing correct results. 3. Testing and Prediction: Allowing the system to make decisions or predictions based on what it has learned. They also learned about different types of ML, such as: \u2022 Supervised Learning: Learning from labeled examples (e.g., identifying pictures of cats and dogs). \u2022 Unsupervised Learning: Finding patterns in unlabeled data (e.g., grouping similar items", "automatically). \u2022 Reinforcement Learning: Learning through trial and error, much like how humans learn new skills. The discussion also included the connection between AI, robotics, and IoT\u2014how these technologies combine to create smart systems that can sense, learn, and act. For instance, an IoT-enabled robot could use AI to make decisions or adjust its behavior based on data from sensors. Students were fascinated to see how AI and ML are already being used in self-driving cars, medical diagnosis, smart assistants, and even games. This topic encouraged them to think about how they could use AI to solve real-world problems in the future. 6. Practical Learning and Creativity Throughout the workshop, emphasis was placed on learning by doing. Students were divided into small teams to work on mini-projects that combined different technologies. They built small circuits, tested sensors, and wrote basic programs. This teamwork approach helped them share ideas, solve problems together, and build confidence in using technology. By the end of the workshop, students understood how electronics, coding, and cloud computing connect to form complete digital systems. The workshop also nurtured creativity and innovation. Students were encouraged to imagine new applications\u2014like smart classrooms, energy-saving systems, and assistive robots for the elderly. They learned that digital intelligence is not only about machines, but about using technology responsibly to improve human life. Apractical example of machine learning explained below Functional Explanation of the Photo Identification Program This program is designed to train a computer to recognize and classify images automatically using the principles of Artificial Intelligence (AI) and Machine Learning (ML). It works on the concept of teaching a computer to \u201csee\u201d patterns in pictures and make decisions, much like how humans identify objects or faces. 1. Purpose of the Program The main purpose of the program is to create an intelligent", "photo identification system. The system studies many example images during a training phase and then learns how to recognize which category a new image belongs to. For example, if the program is trained with pictures of different types of documents, animals, or faces, it can later identify which type a new, unseen image belongs to. This process is similar to how people learn \u2014 by looking at many examples, recognizing differences, and making conclusions. 2. Functional Components The program works in several stages, each with a clear function: a) Image Collection and Preparation Images are first organized into folders \u2014 one folder for each category. For instance, if the task is to identify different types of ID cards, there might be folders named \u201cPAN\u201d, \u201cAadhaar\u201d, \u201cDriving License\u201d, etc. These folders serve as examples for the computer to learn from. The program then reads these images and prepares them for learning by resizing them to a uniform size and normalizing their brightness and color levels. This makes all images consistent and easier to compare. b) Learning Through Data Augmentation To make the system smarter and more adaptable, the program doesn\u2019t just use the same pictures repeatedly. It automatically creates slightly changed versions of the images by flipping, zooming, or rotating them. This process, called data augmentation, helps the computer learn to recognize objects even if they appear in different positions or lighting conditions. It\u2019s similar to how humans can recognize a friend\u2019s face from different angles or in different photos. c) Training the Model Once the images are ready, the computer starts its training phase. Here, it uses a type of Artificial Intelligence called a Convolutional Neural Network (CNN). A CNN works somewhat like the visual system in the human brain: \u2022 The early layers detect simple shapes (like edges and", "corners). \u2022 The deeper layers recognize more complex patterns (like eyes, letters, or features). \u2022 Finally, the network decides what the image most likely represents. During training, the system repeatedly looks at the images and adjusts its internal settings (called weights) to reduce mistakes. It continues this process through several rounds, called epochs, gradually improving its accuracy. d) Validation and Testing To make sure the computer isn\u2019t just memorizing the images but is truly learning, a separate set of images is used for validation. These images were not shown during training, so they test how well the model performs on new data. The program checks its performance after each round and keeps improving until the results are stable and accurate. e) Model Creation and Storage Once the system reaches a good accuracy level, the learned model \u2014 that is, the \u201cbrain\u201d of the program \u2014 is saved as a digital file. This file contains all the knowledge gained during training and can be reused anytime without repeating the learning process. It can be loaded later to identify new images instantly. 3. Functional Flow of the Program Here\u2019s the overall flow of how the system works: 1. Collect Images: Gather and organize pictures into folders based on categories. 2. Preprocess Images: Resize, normalize, and adjust them for training. 3. Augment Data: Create variations of images to improve learning ability. 4. Train the Model: Use a neural network to recognize patterns in the data. 5. Validate Results: Test performance on unseen images. 6. Save the Model: Store the trained model for future use. 7. Predict New Images: Use the saved model to classify new, unknown pictures. 4. Functional Advantages \u2022 Automation: The program can automatically identify images without human help. \u2022 Adaptability: It can be trained for any type of image \u2014", "documents, plants, faces, or logos. \u2022 Scalability: The same model can learn from thousands of examples and improve with more data. \u2022 Practical Use: It can be used in real-world systems such as attendance tracking, ID verification, or image sorting. 5. Conceptual Understanding for Students This project shows how Machine Learning and Artificial Intelligence are used to teach computers to \u201csee\u201d and \u201cunderstand\u201d images. It connects many digital intelligence concepts: \u2022 Electronics: The idea of sensors capturing images. \u2022 Programming: Writing logical steps for learning and prediction. \u2022 Machine Learning: Training systems using data and feedback. \u2022 Artificial Intelligence: Making smart decisions like a human observer. Through this, students can understand how AI models used in real life\u2014such as face unlock, photo tagging, and traffic sign recognition\u2014are built from simple learning systems like this one. 6. Outcome of the Program After the training is complete, the computer can: \u2022 Recognize images with a certain accuracy. \u2022 Distinguish between different categories automatically. \u2022 Be reused to classify any new image given to it. This demonstrates the power of Digital Intelligence \u2014 where computers learn, adapt, and assist humans in processing large amounts of visual information quickly and accurately. 7. Conclusion The Workshop on Digital Intelligence successfully gave students an early introduction to technologies that are shaping the future. By combining advanced electronics, robotics, IoT, artificial intelligence, and machine learning, the workshop provided a complete and inspiring learning experience. Students not only learned how machines work but also how they can be made intelligent and useful. The sessions bridged the gap between imagination and innovation, showing that even school students can build and understand complex digital systems with the right guidance and curiosity. The workshop concluded with great enthusiasm, and the students expressed excitement about continuing their learning journey in technology and", "innovation. It truly helped them develop the digital intelligence needed for the next generation of problem-solvers, inventors, and creators. Another programme in the same venue below Art Exhibition An art exhibition also arranged nearby . The pencil drawing , charcoal drawing , water colour painting done By ; Abhijith R , Sivadrumam , Peruvaram. Mobile : 8590566698"];
        
        function findAnswer(question) {
            const q = question.toLowerCase().trim();
            
            // Step 1: Exact match in Q&A (highest priority)
            if (qaData[q]) return qaData[q];
            
            // Step 2: Check for specific question patterns
            if (q.includes('art') && q.includes('where')) {
                return qaData['where art exhibition'] || qaData['art exhibition location'] || 'Art exhibition arranged nearby the workshop venue';
            }
            if (q.includes('art') && (q.includes('who') || q.includes('conducted'))) {
                return qaData['who conducted art exhibition'] || qaData['art exhibition artist'] || 'Abhijith R from Sivadrumam, Peruvaram';
            }
            
            // Step 3: Keyword matching with better accuracy
            for (let category in keywords) {
                const categoryKeywords = keywords[category];
                let keywordMatches = 0;
                
                // Count how many keywords match
                for (let keyword of categoryKeywords) {
                    if (q.includes(keyword)) {
                        keywordMatches++;
                    }
                }
                
                // If multiple keywords match or single strong match
                if (keywordMatches >= 2 || (keywordMatches === 1 && categoryKeywords.some(kw => q === kw))) {
                    // Find best matching Q&A for this category
                    let bestMatch = null;
                    let bestScore = 0;
                    
                    for (let qaKey in qaData) {
                        let score = 0;
                        if (qaKey.includes(category)) score += 3;
                        
                        for (let kw of categoryKeywords) {
                            if (qaKey.includes(kw)) score += 2;
                            if (q.includes(kw) && qaKey.includes(kw)) score += 1;
                        }
                        
                        if (score > bestScore) {
                            bestScore = score;
                            bestMatch = qaData[qaKey];
                        }
                    }
                    
                    if (bestMatch) return bestMatch;
                }
            }
            
            // Step 4: Partial match in Q&A keys (improved)
            let bestPartialMatch = null;
            let bestPartialScore = 0;
            
            for (let key in qaData) {
                let score = 0;
                
                // Exact substring match
                if (key.includes(q) || q.includes(key)) score += 5;
                
                // Word-by-word matching
                const keyWords = key.split(' ');
                const qWords = q.split(' ');
                const matches = keyWords.filter(word => qWords.includes(word));
                score += matches.length;
                
                // Bonus for longer matches
                if (matches.length >= keyWords.length / 2) score += 2;
                
                if (score > bestPartialScore && score >= 2) {
                    bestPartialScore = score;
                    bestPartialMatch = qaData[key];
                }
            }
            
            if (bestPartialMatch) return bestPartialMatch;
            
            // Step 5: Search in PDF chunks with better matching
            const words = q.split(' ').filter(w => w.length > 3);
            let bestChunk = null;
            let bestChunkScore = 0;
            
            for (let chunk of pdfChunks) {
                const chunkLower = chunk.toLowerCase();
                let score = 0;
                
                for (let word of words) {
                    if (chunkLower.includes(word)) {
                        score += word.length; // Longer words get higher score
                    }
                }
                
                if (score > bestChunkScore && score >= 8) {
                    bestChunkScore = score;
                    bestChunk = chunk;
                }
            }
            
            if (bestChunk) {
                return bestChunk.substring(0, 300) + '...';
            }
            
            // Step 6: Return helpful message
            return `I don't have specific information about '${question}'. Try asking about: workshop conductor, Arduino, IoT, topics covered, art exhibition, or location.`;
        }
        
        function sendMessage() {
            const input = document.getElementById('input');
            const chat = document.getElementById('chat');
            const question = input.value.trim();
            
            if (!question) return;
            
            chat.innerHTML += '<div class="message user">' + question + '</div>';
            
            const answer = findAnswer(question);
            chat.innerHTML += '<div class="message bot">' + answer + '</div>';
            
            input.value = '';
            chat.scrollTop = chat.scrollHeight;
        }
        
        function ask(question) {
            document.getElementById('input').value = question;
            sendMessage();
        }
        
        document.getElementById('input').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') sendMessage();
        });
    </script>
</body>
</html>
